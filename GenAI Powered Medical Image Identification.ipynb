{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing and Importing Dependencies"
      ],
      "metadata": {
        "id": "j0MeTJaYLFHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils && pip install pdf2image open-clip-torch transformers beautifulsoup4 requests pillow scikit-learn matplotlib seaborn tqdm streamlit -q\n"
      ],
      "metadata": {
        "id": "9kXsGKr-LSTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installed Libraries and Their Use\n",
        "\n",
        "- `open-clip-torch`: Used for extracting visual+text embeddings using the CLIP model for zero-shot or multimodal tasks.\n",
        "- `transformers`: Provides access to pre-trained NLP and vision models (like BERT, ViT) from Hugging Face.\n",
        "- `pdf2image`: Converts PDF pages into images, useful for visual input extraction from documents.\n",
        "- `beautifulsoup4`: Parses and scrapes HTML/XML content, useful for extracting images or text from web pages.\n",
        "- `requests`: Used to send HTTP requests and fetch content from URLs (like PDFs or websites).\n",
        "- `pillow`: A Python Imaging Library for image loading, manipulation, and format conversion.\n",
        "- `scikit-learn`: Provides essential tools for machine learning, evaluation metrics, preprocessing, and modeling.\n",
        "- `matplotlib`: Used for plotting data, confusion matrices, image visualizations, etc.\n",
        "- `seaborn`: Builds on matplotlib to create more attractive and informative statistical graphics.\n",
        "- `tqdm`: Adds progress bars to loops for better tracking of long-running operations.\n"
      ],
      "metadata": {
        "id": "CiYqcAMjMZIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import io\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "fxfYYBaDMOLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\" Using device: {device}\")"
      ],
      "metadata": {
        "id": "bn1u-uBcMlIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Image Extraction Utilities"
      ],
      "metadata": {
        "id": "5M0jibxmURRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageExtractor:\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        self.supported_formats = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
        "\n",
        "    def extract_from_pdf(self, pdf_path, output_dir=\"extracted_images\", dpi=300):\n",
        "        try:\n",
        "            from pdf2image import convert_from_path\n",
        "        except ImportError:\n",
        "            print(\"pdf2image not installed. Run: !apt-get install poppler-utils\")\n",
        "            return []\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        extracted_images = []\n",
        "        try:\n",
        "            pages = convert_from_path(pdf_path, dpi=dpi)\n",
        "            for i, page in enumerate(pages):\n",
        "                image_path = os.path.join(output_dir, f\"pdf_page_{i+1}.jpg\")\n",
        "                page.save(image_path, 'JPEG')\n",
        "                extracted_images.append(image_path)\n",
        "            print(f\"Extracted {len(extracted_images)} images from PDF\")\n",
        "            return extracted_images\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting from PDF: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def extract_from_url(self, url, output_dir=\"extracted_images\", max_images=50):\n",
        "        import requests\n",
        "        from bs4 import BeautifulSoup\n",
        "        from urllib.parse import urljoin, urlparse\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        extracted_images = []\n",
        "        try:\n",
        "            headers = {'User-Agent': 'Mozilla/5.0 ... Chrome/91.0.4472.124 Safari/537.36'}\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            img_tags = soup.find_all('img')\n",
        "            print(f\"Found {len(img_tags)} image tags on webpage\")\n",
        "            for i, img in enumerate(img_tags):\n",
        "                if len(extracted_images) >= max_images:\n",
        "                    break\n",
        "                img_url = img.get('src') or img.get('data-src') or img.get('data-lazy-src')\n",
        "                if not img_url:\n",
        "                    continue\n",
        "                img_url = urljoin(url, img_url)\n",
        "                if any(fmt in img_url.lower() for fmt in self.supported_formats):\n",
        "                    try:\n",
        "                        img_response = requests.get(img_url, headers=headers, timeout=5)\n",
        "                        if img_response.status_code == 200 and len(img_response.content) > 1000:\n",
        "                            filename = f\"web_image_{len(extracted_images)+1}.jpg\"\n",
        "                            image_path = os.path.join(output_dir, filename)\n",
        "                            img_pil = Image.open(io.BytesIO(img_response.content))\n",
        "                            if img_pil.mode in ('RGBA', 'LA', 'P'):\n",
        "                                img_pil = img_pil.convert('RGB')\n",
        "                            if img_pil.size[0] > 2048 or img_pil.size[1] > 2048:\n",
        "                                img_pil.thumbnail((2048, 2048), Image.Resampling.LANCZOS)\n",
        "                            img_pil.save(image_path, 'JPEG', quality=85)\n",
        "                            extracted_images.append(image_path)\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "            print(f\" Extracted {len(extracted_images)} images from URL\")\n",
        "            return extracted_images\n",
        "        except Exception as e:\n",
        "            print(f\" Error extracting from URL: {str(e)}\")\n",
        "            return []\n"
      ],
      "metadata": {
        "id": "aYfMxn0YTwUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Medical Image Classifier (BiomedCLIP)"
      ],
      "metadata": {
        "id": "n7CEqnKEabER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalImageClassifier:\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.preprocess = None\n",
        "        self.tokenizer = None\n",
        "        self.device = device\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            from open_clip import create_model_from_pretrained, get_tokenizer\n",
        "        except ImportError:\n",
        "            print(\"open_clip_torch not installed properly\")\n",
        "            return False\n",
        "        print(\" Loading BiomedCLIP model...\")\n",
        "        try:\n",
        "            self.model, self.preprocess = create_model_from_pretrained(\n",
        "                'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
        "            )\n",
        "            self.tokenizer = get_tokenizer(\n",
        "                'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
        "            )\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "            print(f\"Model loaded successfully on {self.device}\")\n",
        "            # Define prompts and labels\n",
        "            self.templates = [\n",
        "                'this is a photo of', 'this image shows', 'this is an image of', 'a photograph of'\n",
        "            ]\n",
        "            self.medical_labels = [\n",
        "                'medical image', 'X-ray image', 'MRI scan', 'CT scan', 'ultrasound image',\n",
        "                'histopathology image', 'medical photograph', 'radiological image', 'clinical image',\n",
        "                'diagnostic image', 'medical chart', 'anatomical image'\n",
        "            ]\n",
        "            self.non_medical_labels = [\n",
        "                'non-medical image', 'natural photograph', 'landscape photo', 'portrait photo',\n",
        "                'everyday object', 'architectural photo', 'animal photo', 'food photo', 'abstract image',\n",
        "                'general photograph', 'street scene', 'artwork'\n",
        "            ]\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def classify_single_image(self, image_path):\n",
        "        try:\n",
        "            image = Image.open(image_path)\n",
        "            if image.mode != 'RGB':\n",
        "                image = image.convert('RGB')\n",
        "            if image.size[0] > 512 or image.size[1] > 512:\n",
        "              image.thumbnail((512, 512), Image.Resampling.LANCZOS)\n",
        "            image_tensor = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "            all_labels = self.medical_labels + self.non_medical_labels\n",
        "            text_prompts = [\n",
        "                f\"{template} {label}\" for template in self.templates for label in all_labels\n",
        "            ]\n",
        "            text_tokens = self.tokenizer(text_prompts, context_length=256).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                image_features, text_features, logit_scale = self.model(image_tensor, text_tokens)\n",
        "                logits = (logit_scale * image_features @ text_features.t()).detach()\n",
        "                probs = torch.softmax(logits, dim=-1).cpu()\n",
        "                # Aggregate probabilities\n",
        "                num_templates = len(self.templates)\n",
        "                num_labels = len(all_labels)\n",
        "                probs_reshaped = probs.view(num_templates, num_labels)\n",
        "                avg_probs = torch.mean(probs_reshaped, dim=0)\n",
        "                medical_score = torch.sum(avg_probs[:len(self.medical_labels)]).item()\n",
        "                non_medical_score = torch.sum(avg_probs[len(self.medical_labels):]).item()\n",
        "                total_score = medical_score + non_medical_score\n",
        "                medical_confidence = medical_score / total_score if total_score > 0 else 0.5\n",
        "                prediction = \"medical\" if medical_confidence > 0.5 else \"non-medical\"\n",
        "                confidence = max(medical_confidence, 1 - medical_confidence)\n",
        "                return {\n",
        "                    'prediction': prediction,\n",
        "                    'confidence': confidence,\n",
        "                    'medical_score': medical_confidence,\n",
        "                    'non_medical_score': 1 - medical_confidence\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(f\"Error classifying {image_path}: {str(e)}\")\n",
        "            return {'prediction': 'error', 'confidence': 0.0, 'medical_score': 0.0, 'non_medical_score': 0.0}\n",
        "\n",
        "    def classify_batch(self, image_paths, batch_size=8):\n",
        "        results = []\n",
        "        print(f\" Classifying {len(image_paths)} images...\")\n",
        "        for i in tqdm(range(0, len(image_paths), batch_size)):\n",
        "            batch_paths = image_paths[i:i+batch_size]\n",
        "            for image_path in batch_paths:\n",
        "                result = self.classify_single_image(image_path)\n",
        "                result['image_path'] = image_path\n",
        "                result['image_name'] = os.path.basename(image_path)\n",
        "                results.append(result)\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "vMjeeFoyaXVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Pipeline: Process Input Source"
      ],
      "metadata": {
        "id": "rnuiokV_iOQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_input(input_source, source_type='auto', extractor=None, classifier=None):\n",
        "\n",
        "    if extractor is None or classifier is None:\n",
        "        print(\"Extractor and classifier must be initialized\")\n",
        "        return None\n",
        "    print(f\" Starting processing pipeline...\")\n",
        "    start_time = time.time()\n",
        "    # Determine source type\n",
        "    if source_type == 'auto':\n",
        "        if input_source.lower().endswith('.pdf'):\n",
        "            source_type = 'pdf'\n",
        "        elif input_source.startswith(('http://', 'https://')):\n",
        "            source_type = 'url'\n",
        "        else:\n",
        "            print(\"Cannot determine input type. Please specify 'pdf' or 'url'\")\n",
        "            return None\n",
        "    if source_type == 'pdf':\n",
        "        print(f\"Processing PDF: {input_source}\")\n",
        "        image_paths = extractor.extract_from_pdf(input_source)\n",
        "    elif source_type == 'url':\n",
        "        print(f\"Processing URL: {input_source}\")\n",
        "        image_paths = extractor.extract_from_url(input_source)\n",
        "    else:\n",
        "        print(\"Invalid source type\")\n",
        "        return None\n",
        "    if not image_paths:\n",
        "        print(\"No images extracted\")\n",
        "        return None\n",
        "    results = classifier.classify_batch(image_paths)\n",
        "    # Generate summary\n",
        "    medical_count = sum(1 for r in results if r['prediction'] == 'medical')\n",
        "    non_medical_count = sum(1 for r in results if r['prediction'] == 'non-medical')\n",
        "    error_count = sum(1 for r in results if r['prediction'] == 'error')\n",
        "    processing_time = time.time() - start_time\n",
        "    print(f\"\\n Processing Complete!\")\n",
        "    print(f\"   Total images processed: {len(results)}\")\n",
        "    print(f\"   Medical images: {medical_count}\")\n",
        "    print(f\"   Non-medical images: {non_medical_count}\")\n",
        "    print(f\"   Errors: {error_count}\")\n",
        "    print(f\"   Processing time: {processing_time:.2f} seconds\")\n",
        "    if len(results) > 0:\n",
        "        print(f\"   Average time per image: {processing_time/len(results):.2f} seconds\")\n",
        "    results_df = pd.DataFrame(results)\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_file = f\"classification_results_{timestamp}.csv\"\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"   Results saved to: {output_file}\")\n",
        "    return {\n",
        "        'results': results,\n",
        "        'summary': {\n",
        "            'total_images': len(results),\n",
        "            'medical_count': medical_count,\n",
        "            'non_medical_count': non_medical_count,\n",
        "            'error_count': error_count,\n",
        "            'processing_time': processing_time,\n",
        "            'avg_time_per_image': processing_time/len(results) if len(results) > 0 else 0\n",
        "        },\n",
        "        'output_file': output_file\n",
        "    }\n"
      ],
      "metadata": {
        "id": "_rNm1wGRac_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Result Visualization"
      ],
      "metadata": {
        "id": "hrdfCIDXiqCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(results, max_images=12):\n",
        "    \"\"\"Visualize classification results\"\"\"\n",
        "    if 'results' in results:\n",
        "        display_results = results['results'][:max_images]\n",
        "    else:\n",
        "        display_results = results[:max_images]\n",
        "    n_cols = 4\n",
        "    n_rows = (len(display_results) + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
        "    if n_rows == 1 and n_cols == 1:\n",
        "        axes = [axes]\n",
        "    elif n_rows == 1 or n_cols == 1:\n",
        "        axes = axes.flatten()\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "    for i, result in enumerate(display_results):\n",
        "        if i >= len(axes):\n",
        "            break\n",
        "        try:\n",
        "            img = Image.open(result['image_path'])\n",
        "            axes[i].imshow(img)\n",
        "            prediction = result['prediction']\n",
        "            confidence = result['confidence']\n",
        "            color = 'green' if prediction in ['medical', 'non-medical'] else 'red'\n",
        "            title = f\"{prediction.title()}\\nConf: {confidence:.3f}\"\n",
        "            axes[i].set_title(title, color=color, fontweight='bold')\n",
        "            axes[i].axis('off')\n",
        "        except Exception as e:\n",
        "            axes[i].text(0.5, 0.5, f\"Error loading\\n{result['image_name']}\",\n",
        "                        ha='center', va='center', transform=axes[i].transAxes)\n",
        "            axes[i].axis('off')\n",
        "    # Hide empty subplots\n",
        "    for i in range(len(display_results), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "9NmLGdSsiNaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Testing & Evaluation"
      ],
      "metadata": {
        "id": "kvOnu-8Niyst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Medical:\", len(os.listdir(\"/content/sample_data/medical\")))\n",
        "print(\"Non-Medical:\", len(os.listdir(\"/content/sample_data/non_medical\")))\n"
      ],
      "metadata": {
        "id": "moD_NMXYxW2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_test_data(medical_dir, non_medical_dir):\n",
        "    test_data = []\n",
        "    # Medical\n",
        "    for fname in os.listdir(medical_dir):\n",
        "        img_path = os.path.join(medical_dir, fname)\n",
        "        if os.path.isfile(img_path):\n",
        "            test_data.append((img_path, 'medical'))\n",
        "    # Non-medical\n",
        "    for fname in os.listdir(non_medical_dir):\n",
        "        img_path = os.path.join(non_medical_dir, fname)\n",
        "        if os.path.isfile(img_path):\n",
        "            test_data.append((img_path, 'non-medical'))\n",
        "    return test_data\n"
      ],
      "metadata": {
        "id": "-dKW0YMXB-B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_dir = \"/content/sample_data/medical\"\n",
        "non_medical_dir = \"/content/sample_data/non_medical\"\n",
        "test_data = prepare_test_data(medical_dir, non_medical_dir)\n"
      ],
      "metadata": {
        "id": "PxTazKkgJV1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "rqTWuE05C5JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluate_model(test_data, classifier):\n",
        "\n",
        "    image_paths = [item[0] for item in test_data]\n",
        "    true_labels = [item[1] for item in test_data]\n",
        "    results = classifier.classify_batch(image_paths)\n",
        "    valid_results = [(r, true_labels[i]) for i, r in enumerate(results) if r['prediction'] != 'error']\n",
        "    if not valid_results:\n",
        "        print(\"No valid predictions to evaluate\")\n",
        "        return None\n",
        "    predictions = [r[0]['prediction'] for r in valid_results]\n",
        "    valid_true_labels = [r[1] for r in valid_results]\n",
        "\n",
        "    precision = precision_score(valid_true_labels, predictions, pos_label='medical')\n",
        "    recall = recall_score(valid_true_labels, predictions, pos_label='medical')\n",
        "    cm = confusion_matrix(valid_true_labels, predictions)\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    return precision, recall, cm\n"
      ],
      "metadata": {
        "id": "UWM_ruXNivy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_model(test_data, classifier)\n",
        "\n"
      ],
      "metadata": {
        "id": "p2-OjT0XzQGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Main Execution Block"
      ],
      "metadata": {
        "id": "s9KOR2F5jMAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = ImageExtractor()\n",
        "classifier = MedicalImageClassifier()\n",
        "classifier.load_model()\n"
      ],
      "metadata": {
        "id": "oLuT4S32FTJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Medical Image Classification\")\n",
        "\n",
        "    extractor = ImageExtractor()\n",
        "    classifier = MedicalImageClassifier()\n",
        "    if not classifier.load_model():\n",
        "        print(\"Failed to load model.\")\n",
        "        exit(1)\n",
        "    print(\"\\n System ready! You can now:\")\n",
        "    print(\"1. Process PDF: process_input('mi.pdf', extractor=extractor, classifier=classifier)\")\n",
        "    print(\"2. Process URL: process_input('Wesbite link', extractor=extractor, classifier=classifier)\")\n",
        "    print(\"3. Evaluate: test_data = prepare_test_data('medical_dir', 'non_medical_dir')\")\n",
        "    print(\"             evaluate_model(test_data, classifier)\")\n"
      ],
      "metadata": {
        "id": "fwaE01rbi290"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = process_input('mi.pdf', extractor=extractor, classifier=classifier)\n"
      ],
      "metadata": {
        "id": "xOUYolGgjQ7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_results(results)\n"
      ],
      "metadata": {
        "id": "-3Xs0mHLxaQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83jsLC6ix5_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}